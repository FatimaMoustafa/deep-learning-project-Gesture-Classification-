{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  1.Initial Setup, Kaggle Connection, and Dat Download"
      ],
      "metadata": {
        "id": "B7pfqxx30m9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TARGET_SIZE = (96, 96)\n",
        "INPUT_SHAPE = (TARGET_SIZE[0], TARGET_SIZE[1], 3)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS_PHASE_1 = 20\n",
        "EPOCHS_PHASE_2 = 10\n",
        "LEARNING_RATE_PHASE_1 = 0.001\n",
        "LEARNING_RATE_PHASE_2 = 0.0001\n",
        "\n",
        "KAGGLE_CREDENTIALS_PATH = \"/content/drive/MyDrive/Kaggle/kaggle.json\"\n",
        "KAGGLE_DATASET_ID = \"gti-upm/leapgestrecog\"\n",
        "\n",
        "DOWNLOAD_DIR = \"/content/leap_gesture_data\"\n",
        "\n",
        "DATA_ROOT_PATH_RAW_BASE = os.path.join(DOWNLOAD_DIR, 'leapgestrecog')\n",
        "FIXED_ROOT_PATH = '/content/leap_gesture_data/fixed_data'\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/Kaggle_Gesture_Dataset/best_resnet50_leap_model.h5\"\n",
        "\n",
        "if os.path.exists(DOWNLOAD_DIR):\n",
        "    shutil.rmtree(DOWNLOAD_DIR)\n",
        "    print(f\"Removed previous data directory: {DOWNLOAD_DIR}\")\n",
        "if os.path.exists(FIXED_ROOT_PATH):\n",
        "    shutil.rmtree(FIXED_ROOT_PATH)\n",
        "    print(f\"Removed previous fixed directory: {FIXED_ROOT_PATH}\")\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n--- Setting up Kaggle API and downloading data ---\")\n",
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "if not os.path.exists(\"/root/.kaggle\"):\n",
        "    os.makedirs(\"/root/.kaggle\")\n",
        "\n",
        "try:\n",
        "    shutil.copy(KAGGLE_CREDENTIALS_PATH, \"/root/.kaggle/kaggle.json\")\n",
        "    os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "    print(\"Kaggle API key configured successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"FATAL ERROR: Kaggle key not found at {KAGGLE_CREDENTIALS_PATH}. Please check the path.\")\n",
        "    exit()\n",
        "\n",
        "os.makedirs(DOWNLOAD_DIR)\n",
        "print(\"Downloading dataset...\")\n",
        "!kaggle datasets download -d {KAGGLE_DATASET_ID} -p {DOWNLOAD_DIR} --unzip\n",
        "print(f\"Dataset downloaded and unzipped to {DOWNLOAD_DIR}\")"
      ],
      "metadata": {
        "id": "lf0ECZwZS8_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf65659e-e6b9-4fba-f496-3be0dacd1342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed previous data directory: /content/leap_gesture_data\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "--- Setting up Kaggle API and downloading data ---\n",
            "FATAL ERROR: Kaggle key not found at /content/drive/MyDrive/Kaggle/kaggle.json. Please check the path.\n",
            "Downloading dataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n",
            "Dataset downloaded and unzipped to /content/leap_gesture_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Defining the Correct Path and Comprehensive Restructuring\n"
      ],
      "metadata": {
        "id": "YMzbmyCS1q2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"\\n--- Starting robust data reorganization to ensure all 20,000 files are moved ---\")\n",
        "\n",
        "\n",
        "DATA_ROOT_PATH_FINAL = os.path.join(DATA_ROOT_PATH_RAW_BASE, 'leapGestRecog')\n",
        "\n",
        "if not os.path.exists(DATA_ROOT_PATH_FINAL):\n",
        "    print(\"CRITICAL: Final raw data path not found. Please check manually!\")\n",
        "\n",
        "    DATA_ROOT_PATH_FINAL = DATA_ROOT_PATH_RAW_BASE\n",
        "else:\n",
        "    print(f\"Using confirmed raw data path: {DATA_ROOT_PATH_FINAL}\")\n",
        "\n",
        "if not os.path.exists(FIXED_ROOT_PATH):\n",
        "    os.makedirs(FIXED_ROOT_PATH)\n",
        "\n",
        "files_moved_count = 0\n",
        "\n",
        "for subject_folder in os.listdir(DATA_ROOT_PATH_FINAL):\n",
        "    subject_path = os.path.join(DATA_ROOT_PATH_FINAL, subject_folder)\n",
        "\n",
        "    if os.path.isdir(subject_path) and subject_folder.isdigit():\n",
        "\n",
        "        for gesture_folder in os.listdir(subject_path):\n",
        "            source_gesture_path = os.path.join(subject_path, gesture_folder)\n",
        "\n",
        "            if os.path.isdir(source_gesture_path):\n",
        "                destination_path = os.path.join(FIXED_ROOT_PATH, gesture_folder)\n",
        "\n",
        "                if not os.path.exists(destination_path):\n",
        "                    os.makedirs(destination_path)\n",
        "\n",
        "\n",
        "                    if filename.endswith('.png'):\n",
        "                        shutil.move(os.path.join(source_gesture_path, filename), destination_path)\n",
        "                        files_moved_count += 1\n",
        "\n",
        "print(f\"Data reorganization complete. Total files moved: {files_moved_count}\")\n",
        "\n",
        "print(f\"\\n--- Final verification of file count ---\")\n",
        "total_files = !find {FIXED_ROOT_PATH} -type f -name \"*.png\" | wc -l\n",
        "try:\n",
        "    total_files_count = int(total_files[0].strip())\n",
        "    print(f\"TOTAL FINAL PNG FILES FOUND: {total_files_count}\")\n",
        "\n",
        "    if total_files_count < 20000:\n",
        "        print(\"CRITICAL WARNING: Files are missing. Expected 20,000. Proceed with caution.\")\n",
        "    else:\n",
        "        print(\"SUCCESS: File count is correct (20,000 files expected).\")\n",
        "\n",
        "except:\n",
        "    print(\"Could not count files automatically.\")"
      ],
      "metadata": {
        "id": "i5JAW0IJTOzG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "80172413-aa89-426c-f748-235deeeb51a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting robust data reorganization to ensure all 20,000 files are moved ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4082262857.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDATA_ROOT_PATH_FINAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT_PATH_RAW_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'leapGestRecog'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT_PATH_FINAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  3. Data Generator Setup\n"
      ],
      "metadata": {
        "id": "JUueWX3k13dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"\\n--- Data Preprocessing and Generator Setup ---\")\n",
        "\n",
        "\n",
        "def grayscale_to_rgb(x):\n",
        "\n",
        "    return tf.concat([x, x, x], axis=-1)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range = 0.15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    FIXED_ROOT_PATH,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    FIXED_ROOT_PATH,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "NUM_CLASSES = train_generator.num_classes\n",
        "print(f\"Number of Gesture Classes detected: {NUM_CLASSES}\")"
      ],
      "metadata": {
        "id": "JDMxQWJEUZNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "044f92d5-05e4-4bce-f00c-507077c4834d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data Preprocessing and Generator Setup ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ImageDataGenerator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3514907269.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m datagen = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrotation_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  4. Build ResNet Model\n"
      ],
      "metadata": {
        "id": "pi0tzOZk1_2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"\\n--- Building ResNet50 Model (Transfer Learning Setup) ---\")\n",
        "\n",
        "\n",
        "def build_resnet_transfer_model_for_leap(num_classes):\n",
        "    input_tensor = Input(shape=(TARGET_SIZE[0], TARGET_SIZE[1], 1))\n",
        "    rgb_like_output = Lambda(grayscale_to_rgb,\n",
        "                             output_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3))(input_tensor)\n",
        "\n",
        "\n",
        "    resnet_base = ResNet50(weights='imagenet',\n",
        "                           include_top=False,\n",
        "                           input_tensor=rgb_like_output,\n",
        "                           name='resnet_base_model')\n",
        "\n",
        "    resnet_base.trainable = False\n",
        "\n",
        "\n",
        "    x = resnet_base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    return Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "resnet_transfer_model = build_resnet_transfer_model_for_leap(NUM_CLASSES)\n",
        "print(\"Model built successfully with frozen ResNet base.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "26p2uUVFDs9L",
        "outputId": "eb7f6072-803a-486a-a6e3-88dc01e589bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building ResNet50 Model (Transfer Learning Setup) ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'NUM_CLASSES' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3359345.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mresnet_transfer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_resnet_transfer_model_for_leap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model built successfully with frozen ResNet base.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NUM_CLASSES' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Initial Training (Phase 1: Classification Head Training)\n"
      ],
      "metadata": {
        "id": "Y9XaIHIC2JoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "callbacks_phase1 = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1),\n",
        "\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001, verbose=1),\n",
        "\n",
        "    ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "resnet_transfer_model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE_PHASE_1),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Phase 1: Training Classification Head ---\")\n",
        "history_phase1 = resnet_transfer_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS_PHASE_1,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks_phase1\n",
        ")"
      ],
      "metadata": {
        "id": "QItpaBVMcm_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.  Performance Optimization (Phase 2: Fine-Tuning)\n"
      ],
      "metadata": {
        "id": "bEMIbw7I2Ryb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def grayscale_to_rgb(x):\n",
        "    return tf.concat([x, x, x], axis=-1)\n",
        "\n",
        "print(\"\\nLoading best model from Phase 1...\")\n",
        "resnet_transfer_model = tf.keras.models.load_model(\n",
        "    MODEL_SAVE_PATH,\n",
        "    custom_objects={'grayscale_to_rgb': grayscale_to_rgb}\n",
        ")\n",
        "\n",
        "\n",
        "for layer in resnet_transfer_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "RESNET_START_INDEX = 2\n",
        "fine_tune_at_resnet_layers = 140\n",
        "freeze_until_index = RESNET_START_INDEX + fine_tune_at_resnet_layers\n",
        "\n",
        "frozen_count = 0\n",
        "for i in range(RESNET_START_INDEX, freeze_until_index):\n",
        "    if i < len(resnet_transfer_model.layers):\n",
        "        layer = resnet_transfer_model.layers[i]\n",
        "        layer.trainable = False\n",
        "        frozen_count += 1\n",
        "\n",
        "print(f\"Total layers unfrozen for Fine-Tuning (ResNet upper layers + Classification Head): {len(resnet_transfer_model.layers) - frozen_count}\")\n",
        "print(f\"Frozen {frozen_count} ResNet layers (indices 2 to {freeze_until_index - 1}).\")\n",
        "\n",
        "total_epochs = EPOCHS_PHASE_1 + EPOCHS_PHASE_2\n",
        "\n",
        "callbacks_phase2 = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.000001, verbose=1),\n",
        "    ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "resnet_transfer_model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE_PHASE_2),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Starting Phase 2: Fine-Tuning (Training upper {len(resnet_transfer_model.layers) - frozen_count} layers) ---\")\n",
        "\n",
        "history_fine = resnet_transfer_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=history_phase1.epoch[-1],\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks_phase2\n",
        ")"
      ],
      "metadata": {
        "id": "97HaDjaCgHau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Final Evaluation and Plotting Charts\n"
      ],
      "metadata": {
        "id": "C8tFMhhy2hsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import itertools\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import the library again\n",
        "\n",
        "def grayscale_to_rgb(x):\n",
        "    return tf.concat([x, x, x], axis=-1)\n",
        "\n",
        "print(\"\\n--- Final Model Evaluation and Visualization (Applying Shuffle=False Fix) ---\")\n",
        "\n",
        "final_model = tf.keras.models.load_model(\n",
        "    MODEL_SAVE_PATH,\n",
        "    custom_objects={'grayscale_to_rgb': grayscale_to_rgb}\n",
        ")\n",
        "\n",
        "\n",
        "eval_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "\n",
        "eval_generator = eval_datagen.flow_from_directory(\n",
        "    FIXED_ROOT_PATH,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "history_combined = {}\n",
        "\n",
        "for key in history_phase1.history.keys():\n",
        "    history_combined[key] = (history_phase1.history[key] + history_fine.history[key])\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "epochs_range = range(len(history_combined['accuracy']))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, history_combined['accuracy'], label='Training Accuracy')\n",
        "plt.plot(epochs_range, history_combined['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "plt.axvline(x=EPOCHS_PHASE_1, color='r', linestyle='--', label='Phase 2 Start')\n",
        "plt.title('Accuracy History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, history_combined['loss'], label='Training Loss')\n",
        "plt.plot(epochs_range, history_combined['val_loss'], label='Validation Loss')\n",
        "plt.axvline(x=EPOCHS_PHASE_1, color='r', linestyle='--', label='Phase 2 Start')\n",
        "plt.title('Loss History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('accuracy_loss_history.png')\n",
        "plt.show()\n",
        "\n",
        "eval_generator.reset()\n",
        "STEP_SIZE_VALID_FULL = eval_generator.samples // eval_generator.batch_size + (eval_generator.samples % eval_generator.batch_size != 0)\n",
        "\n",
        "print(\"\\nCalculating predictions using non-shuffling generator...\")\n",
        "Y_pred = final_model.predict(eval_generator, steps=STEP_SIZE_VALID_FULL, verbose=1)\n",
        "y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "y_true = eval_generator.classes[0:len(y_pred_classes)]\n",
        "class_names = list(eval_generator.class_indices.keys())\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Classification Report (Precision, Recall, F1-Score) after Fine-Tuning\")\n",
        "print(\"================================================================================\\n\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        fmt = '.2f'\n",
        "    else:\n",
        "        fmt = 'd'\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, fmt.format(cm[i, j]),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_confusion_matrix(cm, classes=class_names, title='Confusion Matrix for ResNet50 Fine-Tuning')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.show()\n",
        "\n",
        "loss, accuracy = final_model.evaluate(eval_generator, steps=eval_generator.samples // BATCH_SIZE, verbose=1)\n",
        "\n",
        "print(f\"\\n--- Final Confirmed Performance Summary ---\")\n",
        "print(f\"Final Validation Accuracy (Confirmed): {accuracy * 100:.4f}%\")\n",
        "print(f\"Final Validation Loss (Confirmed): {loss:.4f}\")\n",
        "print(f\"Best model saved to: {MODEL_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "dW4t3ULTjT8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWN7GSdVjrSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}